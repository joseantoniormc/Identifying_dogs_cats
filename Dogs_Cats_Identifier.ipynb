{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4dAhx8-CdhM"
      },
      "source": [
        "##  Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oU4Z_DPCdhM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models,transforms,datasets\n",
        "import time\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A66_r51xCdhS"
      },
      "outputs": [],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KN3FFTFhHQyi"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuej9DPjCdhX"
      },
      "source": [
        "Check if GPU is available and if not change the [runtime](https://www.geeksforgeeks.org/how-to-use-google-colab/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t56d0zbFCdhY"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDLlOjT5Et4p"
      },
      "source": [
        "## Downloading the data\n",
        "\n",
        "The data given on the website [Oxford-IIIT Pet Dataset](http://www.robots.ox.ac.uk/~vgg/data/pets/) is made of two files: `images.tar.gz` and `annotations.tar.gz`. We first need to download and decompress these files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEAr5HNeZCjm"
      },
      "outputs": [],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rnn5pLK6EyJK"
      },
      "outputs": [],
      "source": [
        "%mkdir data\n",
        "# the line below needs to be adapted if not running on google colab\n",
        "%cd ./data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkQKDwnfZCjv"
      },
      "source": [
        "Now that you are in the right directory, you can download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTobJ9vTE37J"
      },
      "outputs": [],
      "source": [
        "!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEHXmG2vZCjy"
      },
      "source": [
        "and uncompress it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsMtmnCbCdhd"
      },
      "outputs": [],
      "source": [
        "!tar zxvf images.tar.gz\n",
        "!tar zxvf annotations.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJXlQ2ojZCj0"
      },
      "source": [
        "Check that everything went correctly!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUlawYthZCj1"
      },
      "outputs": [],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPiTo762ZCj3"
      },
      "source": [
        "## Data wrangling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqNGCio0ZCj3"
      },
      "outputs": [],
      "source": [
        "!head annotations/test.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tejOC_TZZCj5"
      },
      "outputs": [],
      "source": [
        "!head annotations/trainval.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wn-tDnZXZCj7"
      },
      "outputs": [],
      "source": [
        "%mkdir test\n",
        "%mkdir trainval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LwIlPrBZCj9"
      },
      "outputs": [],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgorOf_CZCkA"
      },
      "source": [
        "All the images are in the `./images/` folder and you want to store the data according to the following structure:\n",
        "```bash\n",
        ".\n",
        "├── test\n",
        "|   └── Abyssinian # contains images of Abyssinian from the test set\n",
        "|   └── Bengal # contains images of Bengal from the test set\n",
        "|    ...\n",
        "|   └── american_bulldog # contains images of american bulldog from the test set\n",
        "|    ...\n",
        "├── trainval\n",
        "|   └── Abyssinian # contains images of Abyssinian from the trainval set\n",
        "|   └── Bengal # contains images of Bengal from the trainval set\n",
        "|    ...\n",
        "|   └── american_bulldog # contains images of american bulldog from the trainval set\n",
        "|    ...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fiBsTj9ZCkA"
      },
      "outputs": [],
      "source": [
        "with open('./annotations/test.txt') as fp:\n",
        "    line = fp.readline()\n",
        "    while line:\n",
        "        f,_,_,_ = line.split(' ')\n",
        "        print(f)\n",
        "        line = fp.readline()\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLTktYgZZCkC"
      },
      "source": [
        "Remove the `_201`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQ9j71IsZCkD"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "pat = re.compile(r'_\\d')\n",
        "res,_ = pat.split(f)\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zVpVOpgZCkE"
      },
      "source": [
        "This small piece of code is useful for creating directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YeBT3CbZCkF"
      },
      "outputs": [],
      "source": [
        "# create directory if it does not exist\n",
        "def check_dir(dir_path):\n",
        "    dir_path = dir_path.replace('//','/')\n",
        "    os.makedirs(dir_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0WzlkPUZCkG"
      },
      "source": [
        "Some more functions that will be useful\n",
        "- for moving files around you can use the `shutil` lib, see [here](https://docs.python.org/3.6/library/shutil.html#shutil.copy)\n",
        "- you can use `os.path.join`\n",
        "- have a look at python [f-string](https://cito.github.io/blog/f-strings/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMHRHKe9ZCkH"
      },
      "outputs": [],
      "source": [
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ciu2GLSZCkJ"
      },
      "outputs": [],
      "source": [
        "# Here you read the ./annotations/test.txt file line by line,\n",
        "# extract the name of the corresponding file\n",
        "# copy the file from the ./images folder\n",
        "# store it in the ./text folder at the right subfolder\n",
        "path_test_dataset = 'test/'\n",
        "with open('./annotations/test.txt') as fp:\n",
        "    line = fp.readline()\n",
        "    while line:\n",
        "        f,_,_,_ = line.split(' ')\n",
        "        res,_ = pat.split(f)\n",
        "        path = os.path.join(path_test_dataset,res)\n",
        "        check_dir(path)  # check and make directory\n",
        "        shutil.copy(f'./images/{f}.jpg',os.path.join(path,f'{f}.jpg')) #here we use python f-string\n",
        "        line = fp.readline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4jCU3QSZCkK"
      },
      "outputs": [],
      "source": [
        "# Here you do the same thing as above but for trainval data.\n",
        "path_train_dataset='trainval/'\n",
        "with open('./annotations/trainval.txt') as fp:\n",
        "    line = fp.readline()\n",
        "    while line:\n",
        "        f,_,_,_ = line.split(' ')\n",
        "        res,_ = pat.split(f)\n",
        "        path = os.path.join(path_train_dataset,res)\n",
        "        check_dir(path)\n",
        "        shutil.copy(f'./images/{f}.jpg',os.path.join(path,f'{f}.jpg'))\n",
        "        line = fp.readline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkj3DZjpCdha"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iasXk_FKCdhy"
      },
      "outputs": [],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJRnJgGOCdh4"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/data/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "kwFjoxYEgF8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd data"
      ],
      "metadata": {
        "id": "NgqYFSQIgHn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "J9ePhNKsgJOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8t4vokNrF19p"
      },
      "outputs": [],
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "vgg_format = transforms.Compose([\n",
        "                transforms.CenterCrop(224),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8LMReVECdh-"
      },
      "outputs": [],
      "source": [
        "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), vgg_format)\n",
        "         for x in ['trainval', 'test']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMh7kjEBCdiC"
      },
      "outputs": [],
      "source": [
        "os.path.join(data_dir,'trainval')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8uKAPGAZCkW"
      },
      "source": [
        "We now have 37 different classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9ifn_R7CdiH"
      },
      "outputs": [],
      "source": [
        "dsets['trainval'].classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TB6sTwFuCdiK"
      },
      "outputs": [],
      "source": [
        "dsets['trainval'].class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WefhjZb2CdiQ"
      },
      "outputs": [],
      "source": [
        "dset_sizes = {x: len(dsets[x]) for x in ['trainval', 'test']}\n",
        "dset_sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCLV1YgaCdiT"
      },
      "outputs": [],
      "source": [
        "dset_classes = dsets['trainval'].classes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the trainval data, with `batch_size` of 64, and `num_workers` of 6."
      ],
      "metadata": {
        "id": "JnQwTTtZ0MYC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWnJQiWgGP_R"
      },
      "outputs": [],
      "source": [
        "loader_train = torch.utils.data.DataLoader(dsets['trainval'], batch_size=64, shuffle=True, num_workers=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the test data, with batch_size of 5, and num_workers of 6."
      ],
      "metadata": {
        "id": "TblBXcrd0p4p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN1BKHfDCdig"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "loader_valid = torch.utils.data.DataLoader(dsets['test'], batch_size=5, shuffle=False, num_workers=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQra6Q7CZCkj"
      },
      "source": [
        "Check dataloader and everything is doing fine. Count the number of batches in `loader_valid` (734)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4Be7lSLCdik"
      },
      "outputs": [],
      "source": [
        "count = 1\n",
        "for data in loader_valid:\n",
        "    print(count, end=',')\n",
        "    if count == 1:\n",
        "        inputs_try,labels_try = data\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BvxQqfzCdiq"
      },
      "outputs": [],
      "source": [
        "labels_try"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code should output `torch.Size([5, 3, 224, 224])`."
      ],
      "metadata": {
        "id": "XhkDIfPI009Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLNsfqc8Cdis"
      },
      "outputs": [],
      "source": [
        "inputs_try.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsaL21ouKwd9"
      },
      "source": [
        "A small function to display images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "346yl-gbcLLm"
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n",
        "#   Imshow for Tensor.\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = np.clip(std * inp + mean, 0,1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJbW-QzGCdiv"
      },
      "outputs": [],
      "source": [
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs_try)\n",
        "\n",
        "imshow(out, title=[dset_classes[x] for x in labels_try])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HvFNWJICdiz"
      },
      "outputs": [],
      "source": [
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(loader_train))\n",
        "\n",
        "n_images = 8\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs[0:n_images])\n",
        "\n",
        "imshow(out, title=[dset_classes[x] for x in classes[0:n_images]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOvkYiROCdi7"
      },
      "source": [
        "## 2. Modifying VGG Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load pretrained VGG16 model."
      ],
      "metadata": {
        "id": "Hw7xEPL30-dA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9PsHjXgCdi9"
      },
      "outputs": [],
      "source": [
        "model_vgg = models.vgg16(weights='DEFAULT')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VGG_total_params = sum(p.numel() for p in model_vgg.parameters())\n",
        "VGG_total_params/1000000"
      ],
      "metadata": {
        "id": "1zRY97TbmxkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6QQhwruCdjI"
      },
      "outputs": [],
      "source": [
        "inputs_try , labels_try = inputs_try.to(device), labels_try.to(device)\n",
        "\n",
        "model_vgg = model_vgg.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epMB0UF9CdjM"
      },
      "outputs": [],
      "source": [
        "outputs_try = model_vgg(inputs_try)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOlx7YcPCdjO"
      },
      "outputs": [],
      "source": [
        "outputs_try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrweFfK9k0TW"
      },
      "outputs": [],
      "source": [
        "outputs_try.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3Bktt5PCdjh"
      },
      "source": [
        "### Modifying the last layer and setting the gradient false to all layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8kr3-tjCdji"
      },
      "outputs": [],
      "source": [
        "print(model_vgg)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify the last layer."
      ],
      "metadata": {
        "id": "RvXh9rnrBdGW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQwRKKC-Cdjo"
      },
      "outputs": [],
      "source": [
        "for param in model_vgg.parameters():\n",
        "    param.requires_grad = False\n",
        "model_vgg.classifier._modules['6'] = nn.Linear(4096, 37)\n",
        "model_vgg.classifier._modules['7'] = torch.nn.LogSoftmax(dim = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJ3OenJpCdjp"
      },
      "outputs": [],
      "source": [
        "print(model_vgg.classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ITZFX2MCdju"
      },
      "outputs": [],
      "source": [
        "#move the model to gpu\n",
        "model_vgg = model_vgg.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU9vWWT2CdkN"
      },
      "source": [
        "## Training fully connected module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqp2u3IXCdkO"
      },
      "source": [
        "### Creating loss function and optimizer\n",
        "\n",
        "PyTorch documentation for [NLLLoss](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#nllloss) and the [torch.optim module](https://pytorch.org/docs/stable/optim.html#module-torch.optim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oP1F4yb8CdkO"
      },
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss()\n",
        "lr = 0.001\n",
        "optimizer_vgg = torch.optim.SGD(model_vgg.classifier[6].parameters(),lr = lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tenuLj67CdkS"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nNAUibjCdkS"
      },
      "outputs": [],
      "source": [
        "def train_model(model,dataloader,size,epochs=1,optimizer=None):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        for inputs,classes in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            classes = classes.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs,classes)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            _,preds = torch.max(outputs.data,1)\n",
        "            # statistics\n",
        "            running_loss += loss.data.item()\n",
        "            running_corrects += torch.sum(preds == classes.data)\n",
        "        epoch_loss = running_loss / size\n",
        "        epoch_acc = running_corrects.data.item() / size\n",
        "        print('Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                     epoch_loss, epoch_acc))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Jts2jK1CdkV",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "train_model(model_vgg,loader_train,size=dset_sizes['trainval'],epochs=2,optimizer=optimizer_vgg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkMYIX21Hc1k"
      },
      "outputs": [],
      "source": [
        "def test_model(model,dataloader,size):\n",
        "    model.eval()\n",
        "    predictions = np.zeros(size)\n",
        "    all_classes = np.zeros(size)\n",
        "    all_proba = np.zeros((size,37))\n",
        "    i = 0\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    #print(size)\n",
        "    for inputs,classes in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs,classes)\n",
        "        _,preds = torch.max(outputs.data,1)\n",
        "            # statistics\n",
        "        running_loss += loss.data.item()\n",
        "        running_corrects += torch.sum(preds == classes.data)\n",
        "        predictions[i:i+len(classes)] = preds.to('cpu').numpy()\n",
        "        all_classes[i:i+len(classes)] = classes.to('cpu').numpy()\n",
        "        all_proba[i:i+len(classes),:] = outputs.data.to('cpu').numpy()\n",
        "        i += len(classes)\n",
        "    epoch_loss = running_loss / size\n",
        "    epoch_acc = running_corrects.data.item() / size\n",
        "    print('Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                     epoch_loss, epoch_acc))\n",
        "    return predictions, all_proba, all_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3JjYayKCdkW"
      },
      "outputs": [],
      "source": [
        "predictions, all_proba, all_classes = test_model(model_vgg,loader_valid,size=dset_sizes['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cn6cIwZNCdkY"
      },
      "outputs": [],
      "source": [
        "# Get a batch of validation data\n",
        "inputs, classes = next(iter(loader_valid))\n",
        "\n",
        "out = torchvision.utils.make_grid(inputs[0:n_images])\n",
        "\n",
        "imshow(out, title=[dset_classes[x] for x in classes[0:n_images]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uimC9MvQZClO"
      },
      "source": [
        "Compute the predictions made by your network for `inputs[:n_images]` and the associated probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ghkbm7ByCdke"
      },
      "outputs": [],
      "source": [
        "outputs = model_vgg(inputs[:n_images].to(device))\n",
        "print(torch.exp(outputs))\n",
        "inputs = inputs[:n_images].to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vals_try = model_vgg.features(inputs_try)\n",
        "preds_try = torch.max(vals_try.data,1)"
      ],
      "metadata": {
        "id": "sqnQTPERzp78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LkHVBLrZClQ"
      },
      "outputs": [],
      "source": [
        "preds_try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1qdUtvjCdkg"
      },
      "outputs": [],
      "source": [
        "classes[:n_images]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJrSi9yiZClS"
      },
      "outputs": [],
      "source": [
        "torch.exp(vals_try)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0n0hLxTHc1w"
      },
      "source": [
        "## Speeding up the learning by precomputing features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZegyLN3Hc13"
      },
      "outputs": [],
      "source": [
        "def preconvfeat(dataloader):\n",
        "    conv_features = []\n",
        "    labels_list = []\n",
        "    for data in dataloader:\n",
        "        inputs,labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        x = model_vgg.features(inputs)\n",
        "        conv_features.extend(x.data.cpu().numpy())\n",
        "        labels_list.extend(labels.data.cpu().numpy())\n",
        "    conv_features = np.concatenate([[feat] for feat in conv_features])\n",
        "    return (conv_features,labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQiycgsqHc1_"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "conv_feat_train,labels_train = preconvfeat(loader_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imSeW6-7Hc2D"
      },
      "outputs": [],
      "source": [
        "conv_feat_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3e5bjsuHc2F"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "conv_feat_valid,labels_valid = preconvfeat(loader_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0fpZByOHc2H"
      },
      "source": [
        "### Creating a new data generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpx-uU90Hc2H"
      },
      "outputs": [],
      "source": [
        "dtype=torch.float\n",
        "datasetfeat_train = [[torch.from_numpy(f).type(dtype),torch.tensor(l).type(torch.long)] for (f,l) in zip(conv_feat_train,labels_train)]\n",
        "datasetfeat_train = [(inputs.reshape(-1), classes) for [inputs,classes] in datasetfeat_train]\n",
        "loaderfeat_train = torch.utils.data.DataLoader(datasetfeat_train, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFNC9PyGHc2P"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "train_model(model_vgg.classifier,dataloader=loaderfeat_train,size=dset_sizes['trainval'],epochs=80,optimizer=optimizer_vgg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAV2Ld2TZClc"
      },
      "outputs": [],
      "source": [
        "datasetfeat_valid = [[torch.from_numpy(f).type(dtype),torch.tensor(l).type(torch.long)] for (f,l) in zip(conv_feat_valid,labels_valid)]\n",
        "datasetfeat_valid = [(inputs.reshape(-1), classes) for [inputs,classes] in datasetfeat_valid]\n",
        "loaderfeat_valid = torch.utils.data.DataLoader(datasetfeat_valid, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yg770yZHc2W"
      },
      "outputs": [],
      "source": [
        "predictions, all_proba, all_classes = test_model(model_vgg.classifier,dataloader=loaderfeat_valid,size=dset_sizes['test'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFEjbq3DZClf"
      },
      "source": [
        "## Confusion matrix\n",
        "\n",
        "For 37 classes, plotting a confusion matrix is useful to see the performance of the algorithm per class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUpzljRGZClg"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "def make_fig_cm(cm):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "    tick_marks = np.arange(37);\n",
        "    plt.xticks(tick_marks, dset_classes, rotation=90);\n",
        "    plt.yticks(tick_marks, dset_classes, rotation=0);\n",
        "    plt.tight_layout();\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        coeff = f'{cm[i, j]}'\n",
        "        plt.text(j, i, coeff, horizontalalignment=\"center\", verticalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('Actual');\n",
        "    plt.xlabel('Predicted');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IY_3JDL9ZClh"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(all_classes,predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rE8ARkONZCli"
      },
      "outputs": [],
      "source": [
        "make_fig_cm(cm)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}